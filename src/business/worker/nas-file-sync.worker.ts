import { Injectable, Inject, OnModuleInit, Logger } from '@nestjs/common';
import * as path from 'path';
import { pipeline } from 'stream/promises';
import {
  JOB_QUEUE_PORT,
  Job,
} from '../../infra/queue/job-queue.port';
import {
  DISTRIBUTED_LOCK_PORT,
} from '../../infra/queue/distributed-lock.port';
import {
  PROGRESS_STORAGE_PORT,
  type IProgressStoragePort,
  type SyncProgress,
} from '../../infra/queue/progress-storage.port';
import {
  CACHE_STORAGE_PORT,
} from '../../domain/storage/ports/cache-storage.port';
import {
  NAS_STORAGE_PORT,
} from '../../domain/storage/ports/nas-storage.port';
import {
  FILE_REPOSITORY,
  StorageType,
  AvailabilityStatus,
} from '../../domain/file';
import { FILE_STORAGE_OBJECT_REPOSITORY } from '../../domain/storage';
import { FOLDER_REPOSITORY } from '../../domain/folder';
import { TRASH_REPOSITORY } from '../../domain/trash';
import { SYNC_EVENT_REPOSITORY } from '../../domain/sync-event/repositories/sync-event.repository.interface';
import { SyncEventEntity } from '../../domain/sync-event/entities/sync-event.entity';
import { createProgressStream, createProgressLogger, formatBytes } from '../../common/utils';

import type { IJobQueuePort } from '../../infra/queue/job-queue.port';
import type { IDistributedLockPort } from '../../infra/queue/distributed-lock.port';
import type { ICacheStoragePort } from '../../domain/storage/ports/cache-storage.port';
import type { INasStoragePort } from '../../domain/storage/ports/nas-storage.port';
import type { IFileRepository } from '../../domain/file';
import type { IFileStorageObjectRepository } from '../../domain/storage';
import type { IFolderRepository } from '../../domain/folder';
import type { ITrashRepository } from '../../domain/trash';
import type { ISyncEventRepository } from '../../domain/sync-event/repositories/sync-event.repository.interface';



/**
 * NAS íŒŒì¼ ë™ê¸°í™” Action íƒ€ì…
 */
export type NasFileAction = 'upload' | 'rename' | 'move' | 'trash' | 'restore' | 'purge';

// ===== ì•¡ì…˜ë³„ Job ë°ì´í„° ì¸í„°í˜ì´ìŠ¤ =====

/**
 * ê¸°ë³¸ Job ë°ì´í„° (ëª¨ë“  ì•¡ì…˜ ê³µí†µ)
 */
interface NasFileSyncJobBase {
  /** íŒŒì¼ ID */
  fileId: string;
  /** SyncEvent ìƒíƒœ ì¶”ì ìš© (ì„ íƒì ) */
  syncEventId?: string;
}

/**
 * upload ì•¡ì…˜ Job ë°ì´í„°
 * íŒŒì¼ì„ NASì— ì—…ë¡œë“œ
 */
export interface NasFileUploadJobData extends NasFileSyncJobBase {
  action: 'upload';
}

/**
 * rename ì•¡ì…˜ Job ë°ì´í„°
 * íŒŒì¼ ì´ë¦„ ë³€ê²½
 */
export interface NasFileRenameJobData extends NasFileSyncJobBase {
  action: 'rename';
  /** ê¸°ì¡´ ê°ì²´ í‚¤ */
  oldObjectKey: string;
  /** ìƒˆ ê°ì²´ í‚¤ */
  newObjectKey: string;
}

/**
 * move ì•¡ì…˜ Job ë°ì´í„°
 * íŒŒì¼ ì´ë™
 */
export interface NasFileMoveJobData extends NasFileSyncJobBase {
  action: 'move';
  /** ì†ŒìŠ¤ ê²½ë¡œ */
  sourcePath: string;
  /** íƒ€ê²Ÿ ê²½ë¡œ */
  targetPath: string;
  /** ì›ë³¸ í´ë” ID (ë¡¤ë°±ìš©) */
  originalFolderId: string;
  /** íƒ€ê²Ÿ í´ë” ID */
  targetFolderId: string;
}

/**
 * trash ì•¡ì…˜ Job ë°ì´í„°
 * íŒŒì¼ íœ´ì§€í†µ ì´ë™
 */
export interface NasFileTrashJobData extends NasFileSyncJobBase {
  action: 'trash';
  /** í˜„ì¬ ê°ì²´ í‚¤ */
  currentObjectKey: string;
  /** íœ´ì§€í†µ ê²½ë¡œ */
  trashPath: string;
}

/**
 * restore ì•¡ì…˜ Job ë°ì´í„°
 * íœ´ì§€í†µì—ì„œ íŒŒì¼ ë³µì›
 */
export interface NasFileRestoreJobData extends NasFileSyncJobBase {
  action: 'restore';
  /** íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ID */
  trashMetadataId: string;
  /** ë³µì› ëŒ€ìƒ í´ë” ID */
  restoreTargetFolderId: string;
  /** ì‘ì—… ìˆ˜í–‰ ì‚¬ìš©ì ID */
  userId?: string;
}

/**
 * purge ì•¡ì…˜ Job ë°ì´í„°
 * íŒŒì¼ ì˜êµ¬ ì‚­ì œ
 */
export interface NasFilePurgeJobData extends NasFileSyncJobBase {
  action: 'purge';
  /** íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ID (ì„ íƒ) */
  trashMetadataId?: string;
  /** ì‘ì—… ìˆ˜í–‰ ì‚¬ìš©ì ID */
  userId?: string;
}

/**
 * NAS íŒŒì¼ ë™ê¸°í™” í†µí•© Job ë°ì´í„° íƒ€ì… (Union)
 * 
 * íŒŒì¼ ê¸°ë°˜ í êµ¬ì¡°: NAS_FILE_SYNC:{fileId}
 * - ê°™ì€ íŒŒì¼ì— ëŒ€í•œ ì‘ì—…ì€ ìˆœì°¨ ì²˜ë¦¬ ë³´ì¥
 * - ë‹¤ë¥¸ íŒŒì¼ì— ëŒ€í•œ ì‘ì—…ì€ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
 */
export type NasFileSyncJobData =
  | NasFileUploadJobData
  | NasFileRenameJobData
  | NasFileMoveJobData
  | NasFileTrashJobData
  | NasFileRestoreJobData
  | NasFilePurgeJobData;

/**
 * NAS íŒŒì¼ ë™ê¸°í™” í ì„¤ì •
 */
export const NAS_FILE_SYNC_QUEUE_PREFIX = 'NAS_FILE_SYNC';

/**
 * ë™ì‹œ ì²˜ë¦¬ ìˆ˜ (concurrency)
 * - ë‹¤ë¥¸ íŒŒì¼ì€ ë³‘ë ¬ ì²˜ë¦¬
 * - ê°™ì€ íŒŒì¼ì€ íŒŒì¼ë³„ ë½ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬ ë³´ì¥
 * - í™˜ê²½ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥ (ê¸°ë³¸ê°’: 5)
 */
export const NAS_FILE_SYNC_CONCURRENCY = 5;

/**
 * ëŒ€ìš©ëŸ‰ íŒŒì¼ ë³‘ë ¬ ì—…ë¡œë“œ ì„¤ì •
 */
export const PARALLEL_UPLOAD_CONFIG = {
  /** ë³‘ë ¬ ì—…ë¡œë“œ í™œì„±í™” ì„ê³„ê°’ (100MB ì´ìƒ) */
  THRESHOLD_BYTES: 100 * 1024 * 1024,
  /** ì²­í¬ í¬ê¸° (50MB) */
  CHUNK_SIZE: 50 * 1024 * 1024,
  /** ë™ì‹œ ì²­í¬ ì—…ë¡œë“œ ìˆ˜ */
  PARALLEL_CHUNKS: 4,
  /** ì§„í–‰ë¥  ë¡œê·¸ ì¶œë ¥ ê°„ê²© (%) */
  PROGRESS_LOG_INTERVAL: 10,
};


@Injectable()
export class NasSyncWorker implements OnModuleInit {
  private readonly logger = new Logger(NasSyncWorker.name);

  constructor(
    @Inject(JOB_QUEUE_PORT)
    private readonly jobQueue: IJobQueuePort,
    @Inject(DISTRIBUTED_LOCK_PORT)
    private readonly distributedLock: IDistributedLockPort,
    @Inject(CACHE_STORAGE_PORT)
    private readonly cacheStorage: ICacheStoragePort,
    @Inject(NAS_STORAGE_PORT)
    private readonly nasStorage: INasStoragePort,
    @Inject(FILE_REPOSITORY)
    private readonly fileRepository: IFileRepository,
    @Inject(FILE_STORAGE_OBJECT_REPOSITORY)
    private readonly fileStorageObjectRepository: IFileStorageObjectRepository,
    @Inject(FOLDER_REPOSITORY)
    private readonly folderRepository: IFolderRepository,
    @Inject(TRASH_REPOSITORY)
    private readonly trashRepository: ITrashRepository,
    @Inject(SYNC_EVENT_REPOSITORY)
    private readonly syncEventRepository: ISyncEventRepository,
    @Inject(PROGRESS_STORAGE_PORT)
    private readonly progressStorage: IProgressStoragePort,
  ) { }

  /**
   * SyncEvent ì¡°íšŒ (ì—†ìœ¼ë©´ null)
   */
  private async getSyncEvent(syncEventId?: string): Promise<SyncEventEntity | null> {
    if (!syncEventId) return null;
    return this.syncEventRepository.findById(syncEventId);
  }

  /**
   * SyncEvent ì²˜ë¦¬ ì‹œì‘ (PROCESSING)
   */
  private async markSyncEventProcessing(syncEvent: SyncEventEntity | null): Promise<void> {
    if (!syncEvent) return;
    syncEvent.startProcessing();
    await this.syncEventRepository.save(syncEvent);
  }

  /**
   * SyncEvent ì„±ê³µ ì™„ë£Œ (DONE)
   */
  private async markSyncEventDone(syncEvent: SyncEventEntity | null): Promise<void> {
    if (!syncEvent) return;
    syncEvent.complete();
    await this.syncEventRepository.save(syncEvent);
  }

  /**
   * SyncEvent ì¬ì‹œë„ ì²˜ë¦¬
   * - ì¬ì‹œë„ ê°€ëŠ¥: PENDING ìƒíƒœë¡œ ë¡¤ë°±
   * - ì¬ì‹œë„ ë¶ˆê°€ (í•œë„ ì´ˆê³¼): FAILED ìƒíƒœë¡œ ë§ˆí‚¹ + ì•Œë¦¼
   */
  private async handleSyncEventRetry(
    syncEvent: SyncEventEntity | null,
    error: Error,
    jobData: NasFileSyncJobData,
  ): Promise<void> {
    if (!syncEvent) return;
    
    // ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ (causeê°€ ìˆìœ¼ë©´ ì›ë³¸ ì—ëŸ¬ í¬í•¨)
    const detailMessage = this.extractDetailedErrorMessage(error);
    const shouldRetry = syncEvent.retry(detailMessage);
    await this.syncEventRepository.save(syncEvent);
    if (!shouldRetry) {
      syncEvent.fail(detailMessage);
      await this.syncEventRepository.save(syncEvent);
      this.logSyncFailureAlert(syncEvent, error, jobData);
    }
  }

  /**
   * ì—ëŸ¬ì—ì„œ ìƒì„¸ ë©”ì‹œì§€ ì¶”ì¶œ
   * - causeê°€ ìˆìœ¼ë©´ ì›ë³¸ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨
   * - ì‚¬ìš©ìì—ê²ŒëŠ” ê°„ëµ ë©”ì‹œì§€, DBì—ëŠ” ìƒì„¸ ë©”ì‹œì§€ ì €ì¥
   */
  private extractDetailedErrorMessage(error: Error): string {
    const cause = error.cause as Error | undefined;
    if (cause?.message) {
      return `${error.message}: ${cause.message}`;
    }
    return error.message;
  }

  /**
   * ë™ê¸°í™” ìµœì¢… ì‹¤íŒ¨ ì•Œë¦¼ ë¡œê·¸
   * - 3íšŒ ì¬ì‹œë„ í›„ ìµœì¢… ì‹¤íŒ¨ ì‹œ ê´€ë¦¬ì ì•Œë¦¼ìš© ë¡œê·¸ ì¶œë ¥
   */
  private logSyncFailureAlert(
    syncEvent: SyncEventEntity,
    error: Error,
    jobData: NasFileSyncJobData,
  ): void {
    this.logger.error(
      `[SYNC_FAILURE_ALERT] ` +
      `action=${jobData.action} | fileId=${jobData.fileId} | ` +
      `syncEventId=${syncEvent.id} | error=${error.message}`,
    );
    // TODO: ì¶”í›„ ì•Œë¦¼ ì‹œìŠ¤í…œ ì—°ë™ ì‹œ í™•ì¥ ê°€ëŠ¥ (Slack, Email ë“±)
  }

  async onModuleInit() {
    this.logger.log('Registering NAS sync job processors...');

    // ìƒˆ í†µí•© í: NAS_FILE_SYNC (íŒŒì¼ë³„ ë½ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬ ë³´ì¥)
    // concurrency: ë‹¤ë¥¸ íŒŒì¼ì€ ë³‘ë ¬ ì²˜ë¦¬, ê°™ì€ íŒŒì¼ì€ ë½ìœ¼ë¡œ ìˆœì°¨ ì²˜ë¦¬
    const concurrency = NAS_FILE_SYNC_CONCURRENCY;
    await this.jobQueue.processJobs(
      NAS_FILE_SYNC_QUEUE_PREFIX,
      this.processFileSyncJob.bind(this),
      { concurrency },
    );
    this.logger.log(`NAS_FILE_SYNC queue registered with concurrency: ${concurrency}`);
  }

  /**
   * í†µí•© íŒŒì¼ ë™ê¸°í™” ì‘ì—… ì²˜ë¦¬
   * 
   * íŒŒì¼ë³„ ë½ì„ ì‚¬ìš©í•˜ì—¬ ê°™ì€ íŒŒì¼ì— ëŒ€í•œ ì‘ì—…ì€ ìˆœì°¨ ì²˜ë¦¬ë©ë‹ˆë‹¤.
   * ë‹¤ë¥¸ íŒŒì¼ì— ëŒ€í•œ ì‘ì—…ì€ ë³‘ë ¬ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
   */
  private async processFileSyncJob(job: Job<NasFileSyncJobData>): Promise<void> {
    const { fileId, action } = job.data;
    const lockKey = `file-sync:${fileId}`;
    const jobStartTime = Date.now();
    const shortFileId = fileId.substring(0, 8);

    // ğŸ”µ ì‘ì—… ì‹œì‘ ë¡œê·¸ (ë³‘ë ¬ ì²˜ë¦¬ í™•ì¸ìš©)
    this.logger.log(
      `[PARALLEL] ğŸ“¥ JOB_START | file=${shortFileId}... | action=${action} | jobId=${job.id}`,
    );

    // ğŸŸ¡ ë½ íšë“ ì‹œë„ ë¡œê·¸
    this.logger.log(
      `[PARALLEL] ğŸ” LOCK_WAIT | file=${shortFileId}... | action=${action} | lockKey=${lockKey}`,
    );

    const lockWaitStart = Date.now();

    // íŒŒì¼ë³„ ë½ íšë“ í›„ ì‘ì—… ì‹¤í–‰ (ê°™ì€ íŒŒì¼ì€ ìˆœì°¨ ì²˜ë¦¬)
    await this.distributedLock.withLock(
      lockKey,
      async () => {
        const lockWaitTime = Date.now() - lockWaitStart;

        // ğŸŸ¢ ë½ íšë“ ì„±ê³µ ë¡œê·¸
        this.logger.log(
          `[PARALLEL] ğŸ”“ LOCK_ACQUIRED | file=${shortFileId}... | action=${action} | waitTime=${lockWaitTime}ms`,
        );

        const actionStartTime = Date.now();

        switch (action) {
          case 'upload':
            await this.handleUpload(job as Job<NasFileUploadJobData>);
            break;
          case 'rename':
            await this.handleRename(job as Job<NasFileRenameJobData>);
            break;
          case 'move':
            await this.handleMove(job as Job<NasFileMoveJobData>);
            break;
          case 'trash':
            await this.handleTrash(job as Job<NasFileTrashJobData>);
            break;
          case 'restore':
            await this.handleRestore(job as Job<NasFileRestoreJobData>);
            break;
          case 'purge':
            await this.handlePurge(job as Job<NasFilePurgeJobData>);
            break;
          default:
            this.logger.warn(`Unknown action: ${action}`);
        }

        const actionDuration = Date.now() - actionStartTime;
        const totalDuration = Date.now() - jobStartTime;

        // âœ… ì‘ì—… ì™„ë£Œ ë¡œê·¸
        this.logger.log(
          `[PARALLEL] âœ… JOB_DONE | file=${shortFileId}... | action=${action} | ` +
          `actionTime=${actionDuration}ms | totalTime=${totalDuration}ms | lockWait=${lockWaitTime}ms`,
        );
      },
      { ttl: 60000, waitTimeout: 30000, autoRenew: true, renewIntervalMs: 25000 }, // 60ì´ˆ TTL, 30ì´ˆ ëŒ€ê¸°, 25ì´ˆë§ˆë‹¤ ìë™ ê°±ì‹ 
    );
  }

  // ===== í†µí•© Jobìš© í•¸ë“¤ëŸ¬ ë©”ì„œë“œë“¤ =====

  /**
   * Upload ì•¡ì…˜ ì²˜ë¦¬
   * 
   * íŒŒì¼ í¬ê¸°ì— ë”°ë¼ ì „ëµ ë¶„ê¸°:
   * - ì†Œìš©ëŸ‰ (< 100MB): ìŠ¤íŠ¸ë¦¼ ë°©ì‹ + ì§„í–‰ë¥  ë¡œê¹…
   * - ëŒ€ìš©ëŸ‰ (>= 100MB): ì²­í¬ ë³‘ë ¬ ì—…ë¡œë“œ + ì§„í–‰ë¥  ë¡œê¹…
   */
  private async handleUpload(job: Job<NasFileUploadJobData>): Promise<void> {
    const { fileId, syncEventId } = job.data;
    this.logger.debug(`Handling upload for file: ${fileId}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (!nasObject) {
        this.logger.warn(`NAS storage object not found for file: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      if (nasObject.isAvailable()) {
        this.logger.debug(`File already synced to NAS: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      const file = await this.fileRepository.findById(fileId);
      if (!file) {
        this.logger.warn(`File not found: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      const objectKey = syncEvent?.targetPath || fileId;
      const fileSize = file.sizeBytes;
      const shortFileId = fileId.substring(0, 8);
      const totalChunks = Math.ceil(fileSize / PARALLEL_UPLOAD_CONFIG.CHUNK_SIZE);

      // ì§„í–‰ë¥  ì´ˆê¸°í™” (syncEventIdê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
      if (syncEventId) {
        await this.progressStorage.set(syncEventId, {
          fileId,
          syncEventId,
          eventType: 'CREATE',
          status: 'PROCESSING',
          progress: {
            percent: 0,
            completedChunks: 0,
            totalChunks,
            bytesTransferred: 0,
            totalBytes: fileSize,
          },
          startedAt: new Date().toISOString(),
          updatedAt: new Date().toISOString(),
        });
      }

      // íŒŒì¼ í¬ê¸°ì— ë”°ë¥¸ ì „ëµ ë¶„ê¸°
      if (fileSize >= PARALLEL_UPLOAD_CONFIG.THRESHOLD_BYTES) {
        // ëŒ€ìš©ëŸ‰ íŒŒì¼: ì²­í¬ ë³‘ë ¬ ì—…ë¡œë“œ
        this.logger.log(
          `[PARALLEL_UPLOAD] ğŸš€ Starting parallel upload | file=${shortFileId}... | ` +
          `size=${formatBytes(fileSize)} | chunks=${Math.ceil(fileSize / PARALLEL_UPLOAD_CONFIG.CHUNK_SIZE)}`,
        );
        await this.parallelUploadToNas(fileId, objectKey, fileSize, syncEventId);
      } else {
        // ì†Œìš©ëŸ‰ íŒŒì¼: ìŠ¤íŠ¸ë¦¼ ë°©ì‹ + ì§„í–‰ë¥  ë¡œê¹…
        await this.streamUploadToNas(fileId, objectKey, fileSize);
      }

      nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
      nasObject.updateObjectKey(objectKey);
      await this.fileStorageObjectRepository.save(nasObject);

      // ì§„í–‰ë¥  ì™„ë£Œ ì—…ë°ì´íŠ¸ (syncEventIdê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
      if (syncEventId) {
        await this.progressStorage.update(syncEventId, {
          status: 'DONE',
          progress: {
            percent: 100,
            completedChunks: totalChunks,
            totalChunks,
            bytesTransferred: fileSize,
            totalBytes: fileSize,
          },
        });
      }

      await this.markSyncEventDone(syncEvent);
      this.logger.log(
        `[SYNC_COMPLETE] âœ… Successfully synced to NAS | file=${shortFileId}... | ` +
        `size=${formatBytes(fileSize)} | path=${objectKey}`,
      );
    } catch (error) {
      this.logger.error(`Failed to sync file to NAS: ${fileId}`, error);
      
      // ì§„í–‰ë¥  ì‹¤íŒ¨ ì—…ë°ì´íŠ¸ (syncEventIdê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
      if (syncEventId) {
        await this.progressStorage.update(syncEventId, {
          status: 'FAILED',
          error: (error as Error).message,
        });
      }
      
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  
  /**
   * ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì—…ë¡œë“œ (ì†Œìš©ëŸ‰ íŒŒì¼ìš©)
   * ì§„í–‰ë¥  ë¡œê¹… í¬í•¨
   */
  private async streamUploadToNas(
    fileId: string,
    objectKey: string,
    fileSize: number,
  ): Promise<void> {
    const readStream = await this.cacheStorage.íŒŒì¼ìŠ¤íŠ¸ë¦¼ì½ê¸°(fileId);
    
    // ì§„í–‰ë¥  ë¡œê±° ìƒì„±
    const { callback: progressCallback } = createProgressLogger(
      this.logger,
      fileId,
      'NAS_SYNC',
      PARALLEL_UPLOAD_CONFIG.PROGRESS_LOG_INTERVAL,
    );
    
    // ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    const progressStream = createProgressStream(fileSize, progressCallback);
    
    // íŒŒì´í”„ë¼ì¸: ìºì‹œ â†’ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ â†’ NAS
    await this.nasStorage.íŒŒì¼ìŠ¤íŠ¸ë¦¼ì“°ê¸°(objectKey, readStream.pipe(progressStream));
  }

  /**
   * ì²­í¬ ë³‘ë ¬ ì—…ë¡œë“œ (ëŒ€ìš©ëŸ‰ íŒŒì¼ìš©)
   * 
   * ì²˜ë¦¬ ìˆœì„œ:
   * 1. NASì— íŒŒì¼ ì‚¬ì „ í• ë‹¹ (truncate)
   * 2. ìºì‹œì—ì„œ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
   * 3. ê° ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ NASì— ì“°ê¸° (pwrite)
   */
  private async parallelUploadToNas(
    fileId: string,
    objectKey: string,
    fileSize: number,
    syncEventId?: string,
  ): Promise<void> {
    const { CHUNK_SIZE, PARALLEL_CHUNKS, PROGRESS_LOG_INTERVAL } = PARALLEL_UPLOAD_CONFIG;
    const shortFileId = fileId.substring(0, 8);

    // 1. NASì— íŒŒì¼ ì‚¬ì „ í• ë‹¹
    await this.nasStorage.íŒŒì¼ì‚¬ì „í• ë‹¹(objectKey, fileSize);

    // 2. ì²­í¬ ì •ë³´ ê³„ì‚°
    const totalChunks = Math.ceil(fileSize / CHUNK_SIZE);
    const chunks: Array<{ index: number; start: number; end: number }> = [];
    
    for (let i = 0; i < totalChunks; i++) {
      const start = i * CHUNK_SIZE;
      const end = Math.min(start + CHUNK_SIZE - 1, fileSize - 1);
      chunks.push({ index: i, start, end });
    }

    // 3. ì§„í–‰ë¥  ì¶”ì 
    let completedChunks = 0;
    let lastLoggedPercent = 0;

    // 4. ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ (ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ)
    const processChunk = async (chunk: { index: number; start: number; end: number }) => {
      const { index, start, end } = chunk;
      const chunkSize = end - start + 1;

      // ìºì‹œì—ì„œ ì²­í¬ ë²”ìœ„ ì½ê¸°
      const chunkStream = await this.cacheStorage.íŒŒì¼ë²”ìœ„ìŠ¤íŠ¸ë¦¼ì½ê¸°(fileId, start, end);
      
      // ìŠ¤íŠ¸ë¦¼ì„ ë²„í¼ë¡œ ë³€í™˜
      const buffers: Buffer[] = [];
      for await (const data of chunkStream) {
        buffers.push(data);
      }
      const chunkBuffer = Buffer.concat(buffers);

      // NASì— ì²­í¬ ì“°ê¸°
      await this.nasStorage.ì²­í¬ì“°ê¸°(objectKey, chunkBuffer, start);

      // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
      completedChunks++;
      const percent = Math.round((completedChunks / totalChunks) * 100);
      const bytesTransferred = Math.min(completedChunks * CHUNK_SIZE, fileSize);
      
      if (percent >= lastLoggedPercent + PROGRESS_LOG_INTERVAL || percent === 100) {
        // Progress Storageì— ì§„í–‰ë¥  ì €ì¥ (í´ë¼ì´ì–¸íŠ¸ ì¡°íšŒìš©, syncEventIdê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if (syncEventId) {
          await this.progressStorage.update(syncEventId, {
            status: 'PROCESSING',
            progress: {
              percent,
              completedChunks,
              totalChunks,
              bytesTransferred,
              totalBytes: fileSize,
            },
          });
        }
        
        this.logger.log(
          `[PARALLEL_UPLOAD] ğŸ“Š Progress | file=${shortFileId}... | ${percent}% | ` +
          `chunks=${completedChunks}/${totalChunks}`,
        );
        lastLoggedPercent = Math.floor(percent / PROGRESS_LOG_INTERVAL) * PROGRESS_LOG_INTERVAL;
      }
    };

    // 5. ë³‘ë ¬ ì‹¤í–‰ (ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ)
    const executeInBatches = async () => {
      for (let i = 0; i < chunks.length; i += PARALLEL_CHUNKS) {
        const batch = chunks.slice(i, i + PARALLEL_CHUNKS);
        await Promise.all(batch.map(processChunk));
      }
    };

    await executeInBatches();

    this.logger.log(
      `[PARALLEL_UPLOAD] âœ… All chunks uploaded | file=${shortFileId}... | ` +
      `totalChunks=${totalChunks}`,
    );
  }

  /**
   * Rename ì•¡ì…˜ ì²˜ë¦¬
   */
  private async handleRename(job: Job<NasFileRenameJobData>): Promise<void> {
    const { fileId, oldObjectKey, newObjectKey, syncEventId } = job.data;
    this.logger.debug(`Handling rename for file: ${fileId}, ${oldObjectKey} -> ${newObjectKey}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (!nasObject) {
        this.logger.warn(`NAS storage object not found for file: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      if (nasObject.isAvailable() && nasObject.objectKey === newObjectKey) {
        this.logger.debug(`File already renamed in NAS: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      const targetObjectKey = this.buildRenameTarget(oldObjectKey, newObjectKey);

      // NAS íŒŒì¼ ì´ë™ (ë©±ë“±ì„± ë³´ì¥)
      try {
        await this.nasStorage.íŒŒì¼ì´ë™(oldObjectKey, targetObjectKey);
      } catch (nasError: any) {
        // ì†ŒìŠ¤ê°€ ì—†ê³  ëŒ€ìƒì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì´ì „ ì‹œë„ì—ì„œ ì™„ë£Œëœ ê²ƒ (ë©±ë“±ì„±)
        if (nasError.code === 'ENOENT' || nasError.code === 'EEXIST') {
          this.logger.debug(`File rename already completed (idempotent): ${oldObjectKey} -> ${targetObjectKey}`);
        } else {
          throw nasError;
        }
      }

      nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
      nasObject.updateObjectKey(targetObjectKey);
      await this.fileStorageObjectRepository.save(nasObject);

      await this.markSyncEventDone(syncEvent);
      this.logger.log(`Successfully renamed file in NAS: ${fileId}, ${oldObjectKey} -> ${newObjectKey}`);
    } catch (error) {
      this.logger.error(`Failed to rename file in NAS: ${fileId}`, error);
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  /**
   * Move ì•¡ì…˜ ì²˜ë¦¬
   */
  private async handleMove(job: Job<NasFileMoveJobData>): Promise<void> {
    const { fileId, sourcePath, targetPath, originalFolderId, targetFolderId, syncEventId } = job.data;
    this.logger.debug(`Handling move for file: ${fileId}, ${sourcePath} -> ${targetPath}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (!nasObject) {
        this.logger.warn(`NAS storage object not found for file: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      if (nasObject.isAvailable() && nasObject.objectKey === targetPath) {
        this.logger.debug(`File already moved in NAS: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      const targetFolder = await this.folderRepository.findById(targetFolderId);

      if (!targetFolder || !targetFolder.isActive()) {
        this.logger.warn(`Target folder deleted, reverting file move: ${fileId}`);

        const file = await this.fileRepository.findById(fileId);
        if (file) {
          file.moveTo(originalFolderId);
          await this.fileRepository.save(file);
        }

        nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
        await this.fileStorageObjectRepository.save(nasObject);

        await this.markSyncEventDone(syncEvent);
        this.logger.warn(`File move reverted due to deleted target folder: ${fileId}`);
        return;
      }

      // NAS íŒŒì¼ ì´ë™ (ë©±ë“±ì„± ë³´ì¥)
      try {
        await this.nasStorage.íŒŒì¼ì´ë™(sourcePath, targetPath);
      } catch (nasError: any) {
        // ì†ŒìŠ¤ê°€ ì—†ê³  ëŒ€ìƒì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì´ì „ ì‹œë„ì—ì„œ ì™„ë£Œëœ ê²ƒ (ë©±ë“±ì„±)
        if (nasError.code === 'ENOENT' || nasError.code === 'EEXIST') {
          this.logger.debug(`File move already completed (idempotent): ${sourcePath} -> ${targetPath}`);
        } else {
          throw nasError;
        }
      }

      nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
      nasObject.updateObjectKey(targetPath);
      await this.fileStorageObjectRepository.save(nasObject);

      await this.markSyncEventDone(syncEvent);
      this.logger.log(`Successfully moved file in NAS: ${fileId}, ${sourcePath} -> ${targetPath}`);
    } catch (error) {
      this.logger.error(`Failed to move file in NAS: ${fileId}`, error);
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  /**
   * Trash ì•¡ì…˜ ì²˜ë¦¬
   */
  private async handleTrash(job: Job<NasFileTrashJobData>): Promise<void> {
    const { fileId, currentObjectKey, trashPath, syncEventId } = job.data;
    this.logger.debug(`Handling trash for file: ${fileId}, ${currentObjectKey} -> ${trashPath}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (!nasObject) {
        this.logger.warn(`NAS storage object not found for file: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      if (nasObject.isAvailable() && nasObject.objectKey === trashPath) {
        this.logger.debug(`File already moved to trash in NAS: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      if (nasObject.leaseCount > 0) {
        this.logger.warn(`File is being downloaded, retrying later: ${fileId}, leaseCount: ${nasObject.leaseCount}`);
        throw new Error(`FILE_IN_USE: leaseCount=${nasObject.leaseCount}`);
      }

      // NAS íŒŒì¼ íœ´ì§€í†µ ì´ë™ (ë©±ë“±ì„± ë³´ì¥)
      try {
        await this.nasStorage.íŒŒì¼ì´ë™(currentObjectKey, trashPath);
      } catch (nasError: any) {
        // ì†ŒìŠ¤ê°€ ì—†ê³  ëŒ€ìƒì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì´ì „ ì‹œë„ì—ì„œ ì™„ë£Œëœ ê²ƒ (ë©±ë“±ì„±)
        if (nasError.code === 'ENOENT' || nasError.code === 'EEXIST') {
          this.logger.debug(`File trash already completed (idempotent): ${currentObjectKey} -> ${trashPath}`);
        } else {
          throw nasError;
        }
      }

      nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
      nasObject.updateObjectKey(trashPath);
      await this.fileStorageObjectRepository.save(nasObject);

      await this.markSyncEventDone(syncEvent);
      this.logger.log(`Successfully moved file to trash in NAS: ${fileId}, ${currentObjectKey} -> ${trashPath}`);
    } catch (error) {
      this.logger.error(`Failed to move file to trash in NAS: ${fileId}`, error);
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  /**
   * Restore ì•¡ì…˜ ì²˜ë¦¬ (íœ´ì§€í†µì—ì„œ íŒŒì¼ ë³µì›)
   *
   * 1. íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
   * 2. íŒŒì¼ ì—”í‹°í‹° ì¡°íšŒ
   * 3. ëŒ€ìƒ í´ë” ìœ íš¨ì„± í™•ì¸
   * 4. NASì—ì„œ íœ´ì§€í†µ â†’ ì›ë˜ ê²½ë¡œë¡œ íŒŒì¼ ì´ë™
   * 5. íŒŒì¼ ìƒíƒœ ë³µì› (TRASHED -> ACTIVE)
   * 6. íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ì‚­ì œ
   */
  private async handleRestore(job: Job<NasFileRestoreJobData>): Promise<void> {
    const { fileId, syncEventId, trashMetadataId, restoreTargetFolderId } = job.data;
    this.logger.debug(`Handling restore for file: ${fileId}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      // 1. íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
      const trashMetadata = await this.trashRepository.findById(trashMetadataId);
      if (!trashMetadata) {
        this.logger.warn(`TrashMetadata not found: ${trashMetadataId}`);
        if (syncEvent) {
          syncEvent.fail('TRASH_METADATA_NOT_FOUND');
          await this.syncEventRepository.save(syncEvent);
        }
        return;
      }

      // 2. íŒŒì¼ ì¡°íšŒ
      const file = await this.fileRepository.findById(fileId);
      if (!file) {
        this.logger.warn(`File not found: ${fileId}`);
        if (syncEvent) {
          syncEvent.fail('FILE_NOT_FOUND');
          await this.syncEventRepository.save(syncEvent);
        }
        return;
      }

      // 3. ëŒ€ìƒ í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      const targetFolder = await this.folderRepository.findById(restoreTargetFolderId);
      if (!targetFolder || !targetFolder.isActive()) {
        this.logger.warn(`Target folder not found or deleted: ${restoreTargetFolderId}`);
        if (syncEvent) {
          syncEvent.fail('TARGET_FOLDER_NOT_FOUND');
          await this.syncEventRepository.save(syncEvent);
        }
        return;
      }

      // 4. NAS ìŠ¤í† ë¦¬ì§€ ê°ì²´ ì¡°íšŒ ë° íŒŒì¼ ì´ë™
      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (nasObject) {
        const trashPath = nasObject.objectKey;
        // íœ´ì§€í†µ íŒŒì¼ëª…ì—ì„œ trashMetadataId ì ‘ë‘ì‚¬ ì œê±°
        // ì˜ˆ: {trashMetadataId}__20260203023315__333.txt â†’ 20260203023315__333.txt
        const trashFileName = this.extractFileNameFromPath(trashPath);
        const originalNasFileName = this.extractOriginalFileName(trashFileName);

        const folderPath = targetFolder.path.endsWith('/')
          ? targetFolder.path.slice(0, -1)
          : targetFolder.path;
        const restorePath = `${folderPath}/${originalNasFileName}`;

        // NAS íŒŒì¼ ë³µì› ì´ë™ (ë©±ë“±ì„± ë³´ì¥)
        try {
          await this.nasStorage.íŒŒì¼ì´ë™(trashPath, restorePath);
        } catch (nasError: any) {
          // ì†ŒìŠ¤ê°€ ì—†ê³  ëŒ€ìƒì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì´ì „ ì‹œë„ì—ì„œ ì™„ë£Œëœ ê²ƒ (ë©±ë“±ì„±)
          if (nasError.code === 'ENOENT' || nasError.code === 'EEXIST') {
            this.logger.debug(`File restore already completed (idempotent): ${trashPath} -> ${restorePath}`);
          } else {
            throw nasError;
          }
        }

        nasObject.updateObjectKey(restorePath);
        nasObject.updateStatus(AvailabilityStatus.AVAILABLE);
        await this.fileStorageObjectRepository.save(nasObject);
      }

      // 5. íŒŒì¼ ìƒíƒœ ì—…ë°ì´íŠ¸ (Serviceì—ì„œ ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš° ìŠ¤í‚µ)
      if (file.isTrashed()) {
        file.restore(restoreTargetFolderId);
        await this.fileRepository.save(file);
      }

      // 6. íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ì‚­ì œ
      await this.trashRepository.delete(trashMetadataId);

      await this.markSyncEventDone(syncEvent);
      this.logger.log(`Successfully restored file: fileId=${fileId}, targetFolder=${restoreTargetFolderId}`);
    } catch (error) {
      this.logger.error(`Failed to restore file: ${fileId}`, error);
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  /**
   * Purge ì•¡ì…˜ ì²˜ë¦¬ (íŒŒì¼ ì˜êµ¬ ì‚­ì œ)
   *
   * 1. íŒŒì¼ ì¡°íšŒ
   * 2. SeaweedFS(ìºì‹œ)ì—ì„œ íŒŒì¼ ì‚­ì œ
   * 3. NASì—ì„œ íŒŒì¼ ì‚­ì œ
   * 4. ìŠ¤í† ë¦¬ì§€ ê°ì²´ ë ˆì½”ë“œ ì‚­ì œ
   */
  private async handlePurge(job: Job<NasFilePurgeJobData>): Promise<void> {
    const { fileId, syncEventId, trashMetadataId } = job.data;
    this.logger.debug(`Handling purge for file: ${fileId}`);

    const syncEvent = await this.getSyncEvent(syncEventId);

    try {
      await this.markSyncEventProcessing(syncEvent);

      // 1. íŒŒì¼ ì¡°íšŒ
      const file = await this.fileRepository.findById(fileId);
      if (!file) {
        this.logger.warn(`File not found for purge: ${fileId}`);
        await this.markSyncEventDone(syncEvent);
        return;
      }

      // 2. SeaweedFS(ìºì‹œ)ì—ì„œ íŒŒì¼ ì‚­ì œ
      const cacheObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.CACHE,
      );

      if (cacheObject) {
        try {
          await this.cacheStorage.íŒŒì¼ì‚­ì œ(cacheObject.objectKey);
          await this.fileStorageObjectRepository.delete(cacheObject.id);
          this.logger.debug(`Deleted cache object: ${cacheObject.objectKey}`);
        } catch (cacheError) {
          // ìºì‹œ ì‚­ì œ ì‹¤íŒ¨ëŠ” ê²½ê³ ë§Œ (NAS ì‚­ì œ ê³„ì† ì§„í–‰)
          this.logger.warn(`Cache delete failed (continuing): ${fileId}`, cacheError);
        }
      }

      // 3. NASì—ì„œ íŒŒì¼ ì‚­ì œ
      const nasObject = await this.fileStorageObjectRepository.findByFileIdAndType(
        fileId,
        StorageType.NAS,
      );

      if (nasObject) {
        try {
          await this.nasStorage.íŒŒì¼ì‚­ì œ(nasObject.objectKey);
          await this.fileStorageObjectRepository.delete(nasObject.id);
          this.logger.debug(`Deleted NAS object: ${nasObject.objectKey}`);
        } catch (nasError) {
          this.logger.error(`NAS delete failed: ${fileId}`, nasError);
          if (syncEvent) {
            syncEvent.fail(`NAS_DELETE_ERROR: ${(nasError as Error).message}`);
            await this.syncEventRepository.save(syncEvent);
          }
          throw nasError;
        }
      }

      // 4. íŒŒì¼ ìƒíƒœë¥¼ DELETEDë¡œ ë³€ê²½ (NAS ì‘ì—… ì™„ë£Œ í›„)
      file.permanentDelete();
      await this.fileRepository.save(file);
      if (file.isTrashed()) {
        file.permanentDelete();
        await this.fileRepository.save(file);
      }

      // 5. íœ´ì§€í†µ ë©”íƒ€ë°ì´í„° ì‚­ì œ (ìˆëŠ” ê²½ìš°)
      if (trashMetadataId) {
        await this.trashRepository.delete(trashMetadataId);
      }

      await this.markSyncEventDone(syncEvent);
      this.logger.log(`Successfully purged file: fileId=${fileId}`);
    } catch (error) {
      this.logger.error(`Failed to purge file: ${fileId}`, error);
      // SyncEvent ì¬ì‹œë„ ì²˜ë¦¬ (ì¬ì‹œë„ ê°€ëŠ¥ ì‹œ PENDINGìœ¼ë¡œ ë¡¤ë°±)
      await this.handleSyncEventRetry(syncEvent, error as Error, job.data);
      throw error;
    }
  }

  // ===== í—¬í¼ ë©”ì„œë“œë“¤ =====

  /**
   * ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
   * ì˜ˆ: ".trash/1769424469467_333.txt" â†’ "1769424469467_333.txt"
   * ì˜ˆ: "/folder/subfolder/file.txt" â†’ "file.txt"
   */
  private extractFileNameFromPath(filePath: string): string {
    const lastSlashIndex = filePath.lastIndexOf('/');
    if (lastSlashIndex === -1) {
      return filePath;
    }
    return filePath.substring(lastSlashIndex + 1);
  }

  /**
   * íœ´ì§€í†µ íŒŒì¼ëª…ì—ì„œ trashMetadataId ì ‘ë‘ì‚¬ë¥¼ ì œê±°í•˜ì—¬ ì›ë³¸ NAS íŒŒì¼ëª… ì¶”ì¶œ
   * 
   * ì˜ˆ: f60a60a5-fd18-4ca4-b56f-5e2a4cae74dd__20260203023315__333.txt
   *     â†’ 20260203023315__333.txt
   */
  private extractOriginalFileName(trashFileName: string): string {
    const parts = trashFileName.split('__');
    if (parts.length < 2) {
      // '__' êµ¬ë¶„ìê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
      return trashFileName;
    }
    // ì²« ë²ˆì§¸ ë¶€ë¶„(trashMetadataId)ì„ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ '__'ë¡œ ì—°ê²°
    return parts.slice(1).join('__');
  }

  /**
   * rename ëŒ€ìƒ objectKey ê³„ì‚°
   * - ê¸°ì¡´ íƒ€ì„ìŠ¤íƒ¬í”„(prefix)ë¥¼ ìœ ì§€
   * - ìƒˆ íŒŒì¼ëª…ë§Œ êµì²´
   */
  private buildRenameTarget(oldObjectKey: string, newObjectKey: string): string {
    const oldDir = path.posix.dirname(oldObjectKey);
    const oldBase = path.posix.basename(oldObjectKey);
    const newBase = path.posix.basename(newObjectKey);

    const { prefix: oldPrefix, separator: oldSep } = this.parseTimestampPrefix(oldBase);
    const newFileName = this.extractFileName(newBase);
    const targetBase = oldPrefix ? `${oldPrefix}${oldSep}${newFileName}` : newFileName;

    return oldDir === '.' ? targetBase : path.posix.join(oldDir, targetBase);
  }

  private parseTimestampPrefix(fileName: string): { prefix: string | null; separator: string } {
    if (fileName.includes('__')) {
      const [prefix] = fileName.split('__');
      return { prefix, separator: '__' };
    }
    const underscoreIndex = fileName.indexOf('_');
    if (underscoreIndex > 0) {
      const prefix = fileName.substring(0, underscoreIndex);
      if (/^\d{10,}$/.test(prefix)) {
        return { prefix, separator: '_' };
      }
    }
    return { prefix: null, separator: '_' };
  }

  private extractFileName(fileName: string): string {
    if (fileName.includes('__')) {
      return fileName.split('__').slice(1).join('__');
    }
    const underscoreIndex = fileName.indexOf('_');
    if (underscoreIndex > 0) {
      const prefix = fileName.substring(0, underscoreIndex);
      if (/^\d{10,}$/.test(prefix)) {
        return fileName.substring(underscoreIndex + 1);
      }
    }
    return fileName;
  }
}
